{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started with computer vision by Mnist dataset\n",
        "___\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Computer vision is a field of computer science that deals with the automatic processing of digital images and videos. It has a wide range of applications, including image classification, object detection, and image segmentation.\n",
        "\n",
        "The MNIST dataset is a popular dataset for computer vision beginners. It is a dataset of handwritten digits, where each row in the dataset corresponds to a single image of size 28x28 pixels."
      ],
      "metadata": {
        "collapsed": false,
        "id": "a17f9f9d03ad6433"
      },
      "id": "a17f9f9d03ad6433"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Data Ready Part 1\n",
        "\n",
        "The first step in any computer vision project is to get the data ready. This involves loading the data into a format that can be processed by the computer vision model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "e2e86acee581a606"
      },
      "id": "e2e86acee581a606"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6433e0d3c5aaf65f",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:26.233395600Z",
          "start_time": "2023-10-20T14:24:26.195479Z"
        },
        "id": "6433e0d3c5aaf65f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "torch.cuda.set_device(0)\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "train_data = pd.concat([train_data,pd.get_dummies(train_data['label'])],axis=1)\n",
        "del train_data['label']\n",
        "valid_data = train_data.sample(n=int(len(train_data) * 0.2))\n",
        "train_data = train_data.drop(valid_data.index)\n",
        "valid_data = valid_data.reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "test_data = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:30.882595400Z",
          "start_time": "2023-10-20T14:24:26.203364400Z"
        },
        "id": "474f952fd2b2ebf2"
      },
      "id": "474f952fd2b2ebf2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Generator Function\n",
        "\n",
        "In the following code cell, we have created a simple function called data_gen() which receives data from the MNIST dataset and returns a batch of training data. The batch of training data consists of a tuple of two tensors: labels and images. The labels tensor is a tensor of type torch.float32 containing the digit labels for the images in the batch. The images tensor is a tensor of type torch.float32 containing the pixel values for the images in the batch."
      ],
      "metadata": {
        "collapsed": false,
        "id": "2972724d8613d4d"
      },
      "id": "2972724d8613d4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Define a data generator function\n",
        "def data_gen(x,train=True):\n",
        "    \"\"\"Generates a batch of  data.\"\"\"\n",
        "    images = torch.tensor([[x[f'pixel{28 * i + j}'] for j in range(28)] for i in range(28)], dtype=torch.float64).cuda()\n",
        "    if train :\n",
        "        labels = torch.tensor(x[-10:], dtype=torch.long).cuda()\n",
        "        return images.cpu(),labels.cpu()\n",
        "    return images.cpu()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:30.883424900Z",
          "start_time": "2023-10-20T14:24:30.844833700Z"
        },
        "id": "8fae2f44f9425b3f"
      },
      "id": "8fae2f44f9425b3f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Taking a Sneak Peak at the Data\n",
        "\n",
        "Let's take a sneak peak at the data structure that we generated from data_gen().\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b8a9582f374fd24a"
      },
      "id": "b8a9582f374fd24a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABCUlEQVR4nGNgGGSAEYWnmcMu7s1wet32SxgKeSd//Pv339+/f/9+XcDAwMDAwIKQkz8oy7D9F+N/BgYGw/CPpb+Q9bEf/fd3KROEzZO2QwDF0Bl//y0SwuW01//m8eOS8/r1l5+BgUFARBhTjv34378MDJJNr/99n8iGLiny9+/GlNsf/v799/dvLbok68G/f//9/Xti9ux3f5+Ko8va/vz3cZocAwPD9X//rKBi8EA4rM38/REDAwPD//9vn+JytebHv9txyTGc/Ps3DZdc0b+/s1hxyNn9+/9RDrsUV9nrvz/TsUiYBzKkXf779287Nl3+n1/9+/v3RilWIw2+/v13vk4al0OpCQAFFmtfdKk7ngAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "transform =  T.ToPILImage()\n",
        "print(data_gen(train_data.loc[6])[1])\n",
        "# Convert the PyTorch tensor to a Pillow image\n",
        "(transform(data_gen(train_data.loc[6])[0]/255))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:31.737359400Z",
          "start_time": "2023-10-20T14:24:30.851562800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "7a8f9c829fd9248a",
        "outputId": "718fe864-4381-4f64-fbb9-bf55eec51e4d"
      },
      "id": "7a8f9c829fd9248a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output shows that the labels tensor is a tensor of type torch.float64 containing the digit label for the image. The images tensor is a tensor of type torch.float64 containing the pixel values for the image."
      ],
      "metadata": {
        "collapsed": false,
        "id": "545de79fb13def0e"
      },
      "id": "545de79fb13def0e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "def proc_data_saver(df,train=True):\n",
        "    if train:\n",
        "      images = [torch.tensor(data_gen(df.loc[row])[0] / 255, dtype=torch.float64) for row in range(df.shape[0])]\n",
        "      labels = [torch.tensor(data_gen(df.loc[row])[1], dtype=torch.float64) for row in range(df.shape[0])]\n",
        "\n",
        "      return pd.DataFrame({\"Images\":images,\"labels\":labels})\n",
        "    else:\n",
        "      images = [torch.tensor(data_gen(df.loc[row],False)/ 255, dtype=torch.float64) for row in range(df.shape[0])]\n",
        "      return pd.DataFrame({\"Images\":images})"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:31.759693300Z",
          "start_time": "2023-10-20T14:24:31.736852400Z"
        },
        "id": "f1129082e71d54ca"
      },
      "id": "f1129082e71d54ca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now getting our entire train and test datset into same format for effective use."
      ],
      "metadata": {
        "collapsed": false,
        "id": "fda1be9613db2a6d"
      },
      "id": "fda1be9613db2a6d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the file"
      ],
      "metadata": {
        "collapsed": false,
        "id": "10be872fc4bd7af5"
      },
      "id": "10be872fc4bd7af5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-732df51364ae>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  images = [torch.tensor(data_gen(df.loc[row])[0] / 255, dtype=torch.float64) for row in range(df.shape[0])]\n",
            "<ipython-input-5-732df51364ae>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = [torch.tensor(data_gen(df.loc[row])[1], dtype=torch.float64) for row in range(df.shape[0])]\n",
            "<ipython-input-5-732df51364ae>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  images = [torch.tensor(data_gen(df.loc[row],False)/ 255, dtype=torch.float64) for row in range(df.shape[0])]\n",
            "<ipython-input-5-732df51364ae>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  images = [torch.tensor(data_gen(df.loc[row])[0] / 255, dtype=torch.float64) for row in range(df.shape[0])]\n",
            "<ipython-input-5-732df51364ae>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = [torch.tensor(data_gen(df.loc[row])[1], dtype=torch.float64) for row in range(df.shape[0])]\n"
          ]
        }
      ],
      "source": [
        "new_train_data = proc_data_saver(train_data) #uncomment in first run\n",
        "new_test_data = proc_data_saver(test_data,False) #uncomment in first run\n",
        "new_valid_data = proc_data_saver(valid_data) #uncomment in first run"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:31.759693300Z",
          "start_time": "2023-10-20T14:24:31.743180Z"
        },
        "id": "initial_id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4607c10b-7c4b-4b35-e52c-c7923fe2cf10"
      },
      "id": "initial_id"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#import pickle #uncomment first time running\n",
        "#with open(\"train.pkl\",\"wb\") as f:  #uncomment first time\n",
        "#    pickle.dump(new_train_data,f) #uncomment first time"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:31.759693300Z",
          "start_time": "2023-10-20T14:24:31.749796700Z"
        },
        "id": "4e0af963d36f4222"
      },
      "id": "4e0af963d36f4222"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#with open(\"test.pkl\",\"wb\") as f:  #uncomment first time\n",
        "#    (pickle.dump(new_test_data,f))  #uncomment first time"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:31.823390300Z",
          "start_time": "2023-10-20T14:24:31.751884900Z"
        },
        "id": "54297c71d5e7c642"
      },
      "id": "54297c71d5e7c642"
    },
    {
      "cell_type": "code",
      "source": [
        "#with open(\"valid.pkl\",\"wb\") as f:  #uncomment first time\n",
        "#    (pickle.dump(new_valid_data,f))  #uncomment first time"
      ],
      "metadata": {
        "id": "PSU06ekpRhfS"
      },
      "id": "PSU06ekpRhfS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"train.pkl\",\"rb\") as f:\n",
        "    new_train_data = pickle.load(f)\n",
        "with open(\"test.pkl\",\"rb\") as f:\n",
        "    new_test_data = pickle.load(f)\n",
        "with open(\"valid.pkl\",\"rb\") as f:\n",
        "    new_valid_data = pickle.load(f)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:44.550059600Z",
          "start_time": "2023-10-20T14:24:31.759693300Z"
        },
        "id": "3129d846ce1040cb"
      },
      "id": "3129d846ce1040cb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion of Part 1\n",
        "\n",
        "In this markdown, we have learned how to get the data ready for a computer vision project using the MNIST dataset. We have also created a simple function to generate training data and saving it."
      ],
      "metadata": {
        "collapsed": false,
        "id": "197b2e063e42a6ed"
      },
      "id": "197b2e063e42a6ed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our model Architecture Part 2"
      ],
      "metadata": {
        "collapsed": false,
        "id": "674d67fc158faa9e"
      },
      "id": "674d67fc158faa9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self,H,W):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1,out_channels=2,kernel_size=2,padding=1,dtype=torch.float64)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=2,out_channels=4,kernel_size=2,padding=1,dtype=torch.float64)\n",
        "        self.lin1 =  torch.nn.Linear(in_features=3600,out_features=8*H*W,dtype=torch.float64)\n",
        "        self.lin5 =  torch.nn.Linear(in_features=8*H*W,out_features=10,dtype=torch.float64)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "    def forward(self,x):\n",
        "        x = torch.nn.functional.elu(self.conv1(x))\n",
        "        x = torch.nn.functional.elu(self.conv2(x))\n",
        "        x = torch.flatten(x)\n",
        "        x = torch.nn.functional.elu(self.lin1(x))\n",
        "        x = self.softmax(self.lin5(x))\n",
        "        return x"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:44.570772600Z",
          "start_time": "2023-10-20T14:24:44.550059600Z"
        },
        "id": "94f69a73a5aec9c6"
      },
      "id": "94f69a73a5aec9c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = Model(28,28)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:44.967943100Z",
          "start_time": "2023-10-20T14:24:44.568224Z"
        },
        "id": "fe41e8601a3cb4db"
      },
      "id": "fe41e8601a3cb4db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(2, 4, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
              "  (lin1): Linear(in_features=3600, out_features=6272, bias=True)\n",
              "  (lin5): Linear(in_features=6272, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.to('cuda')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:44.988202700Z",
          "start_time": "2023-10-20T14:24:44.967943100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb1cbfdb60e01c7",
        "outputId": "1d3dc5a3-bb62-499b-d1ef-c930dddc0b1f"
      },
      "id": "edb1cbfdb60e01c7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataloaders Part 3"
      ],
      "metadata": {
        "collapsed": false,
        "id": "e305b5c1f191b1ce"
      },
      "id": "e305b5c1f191b1ce"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Datasets.\n",
        "In Pytorch there are two datasets type available\n",
        "- map-style datasets\n",
        "- iterable-style datasets.\n",
        "map-styled datasets are Datasets which inherits the `torch.utils.data.Dataset` and have `__len__`(for length of dataset) and `__getitem__`(to get particular dataitem) defined.  \n",
        "iterable-styled datasets are Datasets which inherits the `torch.utils.data.IterableDataset` and has `__iter__` (to iterate from one datapoint to another) method defined.\n",
        "-----------\n",
        "Here we will use map-styled dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "db25a03cc278f176"
      },
      "id": "db25a03cc278f176"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Data(torch.utils.data.Dataset):\n",
        "    def __init__(self,df,train=True):\n",
        "        self.train = train\n",
        "        if  self.train:\n",
        "            self.label = df['labels']\n",
        "            self.images = df['Images']\n",
        "        else:\n",
        "            self.images = df['Images']\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            return self.images[index],self.label[index]\n",
        "        return self.images[index]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:44.991710500Z",
          "start_time": "2023-10-20T14:24:44.976548600Z"
        },
        "id": "56f1ebb92e718a9d"
      },
      "id": "56f1ebb92e718a9d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "datasetTrain = Data(new_train_data)\n",
        "datasetTest = Data(new_test_data,False)\n",
        "datasetValid = Data(new_valid_data)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:45.008062700Z",
          "start_time": "2023-10-20T14:24:44.991710500Z"
        },
        "id": "be1d1268cd8e1036"
      },
      "id": "be1d1268cd8e1036"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now simply adding the dataset to respective dataloaders."
      ],
      "metadata": {
        "collapsed": false,
        "id": "b667950d3de8a803"
      },
      "id": "b667950d3de8a803"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# creating train, test dataloader\n",
        "DataLTrain = torch.utils.data.DataLoader(datasetTrain,batch_size=64,shuffle=True,num_workers=4)\n",
        "DataLTest = torch.utils.data.DataLoader(datasetTest,batch_size=64,shuffle=False,num_workers=4)\n",
        "DataLValid = torch.utils.data.DataLoader(datasetValid,batch_size=64,shuffle=True,num_workers=4)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-20T14:24:45.070771700Z",
          "start_time": "2023-10-20T14:24:44.998000900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73f54a7d8773c42f",
        "outputId": "f1556ae2-f453-4c7e-cd5a-4c8b1c752957"
      },
      "id": "73f54a7d8773c42f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______\n",
        "## Choosing loss function and optimiser (Training) Part 4\n",
        "\n",
        "\n",
        "\n",
        "----------------"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1532d876032dceb4"
      },
      "id": "1532d876032dceb4"
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = torch.nn.functional.cross_entropy\n",
        "optimiser = torch.optim.Adam(model.parameters(),lr=0.00001)"
      ],
      "metadata": {
        "id": "SAX0cpHZ1SM7"
      },
      "id": "SAX0cpHZ1SM7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  for (images_train_batch, label_train_batch),(images_valid_batch, label_valid_batch) in zip(DataLTrain,DataLValid):\n",
        "    train = 0\n",
        "    valid = 0\n",
        "    batch = len(label_train_batch)\n",
        "\n",
        "    for image, label in zip(images_train_batch,label_train_batch):\n",
        "        optimiser.zero_grad()\n",
        "        preds = model(image.reshape(-1,28,28).to('cuda',dtype=torch.float64))\n",
        "        loss_train = loss_func(preds,label.to('cuda'))\n",
        "        train += loss_train\n",
        "        loss_train.backward()\n",
        "        optimiser.step()\n",
        "    with torch.inference_mode():\n",
        "      for image, label in zip(images_valid_batch,label_valid_batch):\n",
        "          preds = model(image.reshape(-1,28,28).to('cuda',dtype=torch.float64))\n",
        "          loss_valid = loss_func(preds,label.to('cuda'))\n",
        "          valid += loss_valid\n",
        "  print(f\"|epoch : {epoch}\")\n",
        "  print(f\"|train loss : {train}||valid loss : {valid}\")\n",
        "  train = 0\n",
        "  valid = 0\n"
      ],
      "metadata": {
        "id": "exrn6Nikg_IS"
      },
      "id": "exrn6Nikg_IS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the pytorch model"
      ],
      "metadata": {
        "id": "XHG2WfnfYWr-"
      },
      "id": "XHG2WfnfYWr-"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model.pt\")\n"
      ],
      "metadata": {
        "id": "dg9qEHvehlzV"
      },
      "id": "dg9qEHvehlzV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading pytorch model parameters"
      ],
      "metadata": {
        "id": "Coq7wENIYjiM"
      },
      "id": "Coq7wENIYjiM"
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Model(28,28)\n",
        "model2.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "metadata": {
        "id": "yjla4ByUh8Yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac472fe2-8177-43d7-8aa8-d86a5b253176"
      },
      "id": "yjla4ByUh8Yl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating on some examples"
      ],
      "metadata": {
        "id": "nTSSe7jO3tnz"
      },
      "id": "nTSSe7jO3tnz"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model2.eval()\n",
        "with torch.no_grad():\n",
        "  pred = model2((data_gen(test_data.loc[5],False)/255).reshape(-1,28,28))\n",
        "print(torch.round(pred))\n",
        "\n",
        "(transform(data_gen(test_data.loc[5],False)/255))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "8K-sfrHwIr1f",
        "outputId": "840bd567-7a46-459a-8fe6-a8295ad9bd88"
      },
      "id": "8K-sfrHwIr1f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+ElEQVR4nGNgGDaAEUJ5TpdjmMew99HlT1jUlP399fHf379/719facQEF2WBULIMe9MNVOVkGQxDQnZsmI2iUf/135kQlrL/kb9/Z7AhS875+7cUxhbyfPavCMKEWsD4bhZM8t3B14y3kHVmv6xBcOb/Xc3JLsKK8AoDAwMDg6rHDy/G/wxaKox7ecxsj6H65/zfv3+fvvj794SlsLAlK5pnu3f2WInP+rtTBUtAMDAwMDBYv79qikuO4/1nLVxyvNv/teOSY9D4e08Ip+SMv8E45fz/Pccpx7T8bz5OyYi/HzRQVSOx5Rie3kCRZEFiX9qzBqepmAAAaVVQ+uJSFIEAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.eval()\n",
        "with torch.no_grad():\n",
        "  pred = model2((data_gen(test_data.loc[10],False)/255).reshape(-1,28,28))\n",
        "print(torch.round(pred))\n",
        "\n",
        "(transform(data_gen(test_data.loc[10],False)/255))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "FOSEYqpCJzYt",
        "outputId": "aa21a720-01c7-4d84-8c99-940b6ea2096d"
      },
      "id": "FOSEYqpCJzYt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA50lEQVR4nGNgGORA3KL77v/7PBAOI0LcslaagUFYkoGB4a/kW3RNs/9CwKVuWwZ0nTpHeb5+Z7h+dO2tL5i2rfv7RBNNiAmJfeQ6Lmfyv/ibyMDA4KqATVL079/kthvvf3/N58MqCQULMO18s5mBgeHd7uyVP8WxmOswpcRQnoGBoeXDDlzuYmBgO/nFHd1YOPi1hTMNpyTDSUwHIUAE43cMMYlVmwMZGBgYtJ++EcOQXP73bxEDA4P42r9PYEIscEl2BoaIl/81k8UZ7mJalfkTGkJHLDAlGVJ3//379+/fWiEsclQFAHoEW1VWy2trAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}